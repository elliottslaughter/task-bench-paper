\section{Implementations}
\label{sec:implementation}

\input{t1_systems}

We have implemented Task Bench in the 15 parallel and distributed
programming systems listed in Table~\ref{tab:systems}. These include
traditional HPC programming models: MPI~\cite{MPI} (with bulk
synchronous and point-to-point communication) and MPI+X (with OpenMP
and CUDA); PGAS and actor models: Chapel~\cite{Chapel15},
Charm++~\cite{Charmpp93}, X10~\cite{X1005}; and newer task-based
systems: OmpSs~\cite{OmpSs11}, OpenMP~\cite{OpenMPSpec40} (with task
dependencies), PaRSEC (with \emph{parameterized task graphs}
(PTG)~\cite{PARSEC13} and \emph{dynamic task discovery}
(DTD)~\cite{PARSEC_DTD}), Realm~\cite{Realm14},
Regent~\cite{Regent15}, and StarPU~\cite{StarPU11}. Also, we consider
several systems used in large scale data analytics and workflows:
Dask~\cite{Dask15}, Spark~\cite{Spark10}, Swift/T~\cite{Wozniak13},
and TensorFlow~\cite{TensorFlow15}. We describe the systems, and any
salient details of their Task Bench implementations, in our
supplemental material.

One challenge in targeting such a wide variety of
systems is that the capabilities of the systems vary considerably. For
example, some systems are \emph{implicitly parallel}, and provide some
form of parallelism discovery from sequential programs, whereas others
are \emph{explicitly parallel} and require users to specify the
parallelism in the program. For systems that provide both implicit and explicit parallelism, the form of parallelism used in Task Bench is emphasized in Table~\ref{tab:systems}.

%% The Task
%% Bench implementations are intended to reflect how actual applications
%% would be written in the respective systems. Places where the Task
%% Bench implementations may be unidiomatic are noted below.

%% There are also aspects of some systems that we do not consider. For
%% example, tasks may run on CPUs, GPUs, or any execution resource
%% supported by a programming system. However, the level of support for
%% heterogeneous processors varies widely across programming systems (if it exists at all), so
%% in order to include as many systems as possible in our comparisons, we
%% evaluate Task Bench only on CPUs in this paper.

In all cases, members of the programming systems' teams
were consulted in the development and evaluation of the
corresponding Task Bench implementations. Where assistance was provided, the insights helped ensure that we provide the highest quality implementations for each system.
