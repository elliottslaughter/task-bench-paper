\section{Conclusion}
\label{sec:conclusion}

Task Bench is a new approach for evaluating the performance of
parallel and distributed programming systems. By separating the
specification of a benchmark from implementations in various
programming systems, it is possible to explore a broad space of
application scenarios and to do so with a large number of programming
systems. Our experiments have enabled the following
insights:

\begin{itemize}

\item METG for current distributed programming systems varies by over
  5 orders of magnitude.  Clearly understanding the needed task
  granularity is an important consideration in choosing a programming
  system for a new application.

\item While some systems support task granularities as small as 390~ns, this applies only to trivial dependencies and small CPU-based clusters. A number of factors (non-trivial dependencies, accelerators and cluster sizes in the hundreds of nodes) raise the
  METG that any system can reliably achieve by over an order of magnitude: 100~\textmu{}s is a reasonable bound for most applications running at scale with current technologies.

\item Systems that support asynchronous execution show benefits under
  balanced computation
  and communication, and load imbalance. However, these gains can be nullified by
  high baseline overheads.

\item Systems for large scale data analysis require very large tasks
  (tens of seconds) to scale beyond small node counts,
  reflecting the very coarse tasks and lack of need for strong scaling
  performance in current workloads.

\item Newer task-based systems have performance sufficient for
  weak scaling many HPC workloads, but more work is needed to strong
  scale the most demanding codes.

\end{itemize}

\zap{
We have implemented Task Bench for a broad set of programming systems
spanning large scale data analytics and HPC. However, there are
systems not represented in our evaluation that would be interesting to
consider in the future. These include GASNet~\cite{GASNET07},
Habanero~\cite{Habanero11}, Hadoop~\cite{Hadoop},
HPX~\cite{Kaiser2014}, Nimbus~\cite{Nimbus17}, OCR~\cite{OCR14},
OpenSHMEM~\cite{OpenSHMEM10}, Ray~\cite{Ray18}, and UPC~\cite{UPC99}.
} % zap

Not considered in our analysis is the impact of programming system
features on programmer productivity and performance portability. Most
applications do not operate at the absolute extreme of runtime-limited
performance, and thus may choose to trade overhead for better
usability. Our study helps to quantify the performance side of that
tradeoff so that users can be better informed and developers can see
the impact that features have on the performance of their programming
systems.

\section*{Acknowledgment}

This material is based upon work supported by the U.S. Department of
Energy, Office of Science, Office of ASCR, under the contract number
DE-AC02-76SF00515, by National Science Foundation under Grant
No. ACI-1450300, and the Exascale Computing Project (17-SC-20-SC), a
collaborative effort of the U.S. Department of Energy Office of
Science and the National Nuclear Security Administration, under prime
contract DE- AC05-00OR22725, and UT Battelle subawards 4000151974 and
89233218CNA000001. Experiments on the Cori supercomputer were
supported by the National Energy Research Scientific Computing Center,
a DOE Office of Science User Facility supported by the Office of
Science of the U.S. Department of Energy under Contract
No. DE-AC02-05CH11231, and experiments on Piz Daint were supported by
the Swiss National Supercomputing Centre (CSCS) under project ID d80.
