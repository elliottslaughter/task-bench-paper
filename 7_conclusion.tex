\section{Conclusion}
\label{sec:conclusion}

Task Bench is a new approach for evaluating the performance of
parallel and distributed programming systems. By separating the
specification of a benchmark from implementations in various
programming systems, Task Bench reduces overall developer effort to
$\mathcal{O}(m + n)$ (for $m$ benchmarks on $n$ systems) rather than
$\mathcal{O}(mn)$ as has been the case for all previous
benchmarks that we know of. This has enabled us to explore a broad space of
application scenarios and to do so with a large number of programming
systems. Our experiments have enabled the following
insights:
(1) METG for current distributed programming systems varies by over
  5 orders of magnitude.  Clearly understanding the needed task
  granularity is an important consideration in choosing a programming
  system for a new application.
(2) While some systems support METG(50\%) as small as 390~ns, this applies only to trivial dependencies and small CPU-based clusters. A number of factors (nontrivial dependencies, accelerators and cluster sizes in the hundreds of nodes) raise
  the METGs that can be achieved by over an order of magnitude: 100~\textmu{}s is a reasonable bound for most applications running at scale with current technologies.
(3) Systems that support asynchronous execution show benefits under
  balanced computation
  and communication, and load imbalance. However, these gains can be nullified by
  high baseline overheads.
(4) Systems for large scale data analysis require very large tasks
  (tens of seconds) to scale beyond small node counts,
  reflecting the very coarse tasks and lack of need for strong scaling
  in current workloads.
And (5) Task Bench has proven effective in finding performance issues
  and has lead to substantial improvements in several systems
  we study.

\zap{
We have implemented Task Bench for a broad set of programming systems
spanning large scale data analytics and HPC. However, there are
systems not represented in our evaluation that would be interesting to
consider in the future. These include GASNet~\cite{GASNET07},
Habanero~\cite{Habanero11}, Hadoop~\cite{Hadoop},
HPX~\cite{Kaiser2014}, Nimbus~\cite{Nimbus17}, OCR~\cite{OCR14},
OpenSHMEM~\cite{OpenSHMEM10}, Ray~\cite{Ray18}, and UPC~\cite{UPC99}.
} % zap

Not considered in our analysis is the impact of programming system
features on programmer productivity and performance portability. Most
applications do not operate at the absolute extreme of runtime-limited
performance, and thus may choose to trade overhead for
usability. Our study helps to quantify the performance side of that
tradeoff so that users can be better informed and developers can see
the impact that features have on the performance of their programming
systems.
