\section{Conclusion}
\label{sec:conclusion}

Task Bench is a new approach for evaluating the performance of
parallel and distributed programming systems. By separating the
specification of a benchmark from implementations in various
programming systems, it is possible to explore a broad space of
application scenarios and to do so with a large number of programming
systems. Our experiments have enabled the following
insights:

\begin{itemize}

\item METG for current distributed programming systems varies by over
  5 orders of magnitude.  Clearly understanding the needed task
  granularity is an important consideration in choosing a programming
  system for a new application.

\item While some systems support task granularities as small as 390~ns, this applies only to trivial dependencies and small CPU-based clusters. A number of factors (non-trivial dependencies, accelerators and cluster sizes in the hundreds of nodes) raise the
  METG that any system can reliably achieve by over an order of magnitude: 100~\textmu{}s is a reasonable bound for most applications running at scale with current technologies.

\item Systems that support asynchronous execution show benefits under
  balanced computation
  and communication, and load imbalance. However, these gains can be nullified by
  high baseline overheads.

\item Systems for large scale data analysis require very large tasks
  (tens of seconds) to scale beyond small node counts,
  reflecting the very coarse tasks and lack of need for strong scaling
  performance in current workloads.

\item Task Bench has proven effective in finding performance issues
  and has lead to substantial improvements in several of the systems
  we study.

\end{itemize}

\zap{
We have implemented Task Bench for a broad set of programming systems
spanning large scale data analytics and HPC. However, there are
systems not represented in our evaluation that would be interesting to
consider in the future. These include GASNet~\cite{GASNET07},
Habanero~\cite{Habanero11}, Hadoop~\cite{Hadoop},
HPX~\cite{Kaiser2014}, Nimbus~\cite{Nimbus17}, OCR~\cite{OCR14},
OpenSHMEM~\cite{OpenSHMEM10}, Ray~\cite{Ray18}, and UPC~\cite{UPC99}.
} % zap

Not considered in our analysis is the impact of programming system
features on programmer productivity and performance portability. Most
applications do not operate at the absolute extreme of runtime-limited
performance, and thus may choose to trade overhead for better
usability. Our study helps to quantify the performance side of that
tradeoff so that users can be better informed and developers can see
the impact that features have on the performance of their programming
systems.
