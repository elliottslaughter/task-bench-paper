\section{Evaluation}
\label{sec:evaluation}

\input{e0_flags}

We now present a comprehensive evaluation of Task Bench on up to 256
Haswell nodes of the Cori supercomputer~\cite{Cori}, a Cray XC40
machine. Cori Haswell nodes have 2 sockets with Intel Xeon E5-2698 v3
processors (total of 32 physical cores per node), 128 GB RAM, and a
Cray Aries interconnect. We use GCC 7.3.0 for compiling all Task Bench
implementations, and (where applicable) the system default MPI
implementation, Cray MPICH 7.7.3. Additional versions and flags for the
various systems are shown in Table~\ref{tab:flags}.

\subsection{Peak Performance and Efficiency}

\input{e1_flops}
\input{e2_efficiency}

% Really want this to appear in the next section, but Latex forces it to be placed here to get the layout we want.
\input{e3_metg_compute}

In theory, any system should be able to hit peak efficiency as long as
the kernels are well-written and of sufficiently large granularity. In
practice, achieving peak performance is tricky, subject to a number of
pitfalls, and unfortunately, frequently skipped in evaluations of
runtime system overhead. However, verifying that peak performance is
achieved is important to ensuring that such evaluation of overhead and
efficiency are well-grounded and avoid common mistakes in
configuration.

Figure~\ref{fig:flops} shows the FLOPS achieved with a compute-bound
kernel with varying problem sizes. This is the full version of
Figure~\ref{fig:flops-mpi}. In the best case, we measure peak FLOPS of
$1.26 \times 10^{12}$, which compares favorably with the officially
reported number of $1.2 \times 10^{12}$ \cite{Cori}. For the purposes
of measuring efficiency we use our emperically determined number as
the baseline for 100\% efficiency.

The vast majority of systems achieve at or near peak FLOPS. A number
of systems reserve a number of cores (usually 1 or 2) for internal
runtime usage; these systems take a minor hit in peak FLOPS compared
to systems which use all cores for application tasks. Some of the
slower systems struggle to achieve peak FLOPS, though in most cases
the curves suggest that performance would continue to improve if we
were to run larger problem sizes. Unfortunately, the excessive
computational cost of running such tests makes it prohibitively
expensive to run larger problem sizes. For example, the Spark job in
this configuration ran for over 5 hours.

Figure~\ref{fig:efficiency} shows the efficiency (as a percentage of
peak FLOPS achieved) plotted against task granularity. This plot is
used to calculate METG, as described in Section~\ref{sec:metg}. The
red, dashed line shows the point where 50\% efficiency is achieved.

In most cases, task granularity has plateaued prior to this point,
though a number of systems continue to improve as efficiency continues
to drop. Accounting for this effect is one of the main arguments in
favor of METG with a reasonable efficiency threshold compared to
measuring task scheduling throughput in the presence of empty tasks
(effectively the equivalent of METG(0\%)). Empty tasks permit runtime
systems to make unrealistic tradeoffs which are not applicable to real
application workloads where some degree of efficiency is necessarily a
goal. Reporting numbers with empty tasks therefore gives unfair
advantage to systems that make such unrealistic tradeoffs.

\subsection{Baseline Overhead}

One of the basic questions when considering different programming
systems is how much overhead the system introduces. This can be a
tricky question to answer directly because some systems introduce
overhead \emph{inline} (i.e., by running system internal processes on
the same cores as application tasks), while other systems introduce
overhead \emph{out-of-line} (i.e., by dedicating one or more cores
solely to runtime use). Some systems, like Charm++, Realm, and Regent,
even support both configurations.

To answer this question, we use the METG metric to determine the
smallest task granularity which can be executed at a given level of
efficiency, as a proxy for overhead. Figure~\ref{fig:metg-compute}
shows how METG(50\%) varies with node count for a variety of
dependence patterns supported by Task Bench:

\begin{itemize}
\item Figure~\ref{fig:metg-compute-stencil} is a 1D stencil where each
  task depends on 3 other tasks (including the same point in the
  previous timestep).
\item Figure~\ref{fig:metg-compute-nearest} is a pattern where each
  task depends 5 others, chosen to be as close as possible.
\item Figure~\ref{fig:metg-compute-spread} is a pattern where each
  task depends on 5 others, spread as widely as possible.
\item Figure~\ref{fig:metg-compute-4x-nearest} shows 4 identical
  copies of the nearest dependence pattern executing concurrently.
\end{itemize}

We observe in the results that the baseline overheads of different
systems can vary by over 5 orders of magnitude. It is worth
remembering when considering this metric that this is a \emph{minimum}
effective task granularity. Therefore applications with an average
task granularity of \emph{at least} this value can usually be expected
to execute efficiently. Typical average task granularity will
generally be determined by the application domain being
considered. Most notably, for data analytics workloads being run in
industrial data centers, the higher METG values observed for Spark and
TensorFlow are sufficient. In contrast, for high-performance
scientific simulations, task granularities in the millisecond range
are useful, as such applications communicate (e.g., for halo
exchanges) much more frequently.

\subsection{Scalability}

METG is a useful metric in part because it summarizes the basic task
scheduling overhead of a system in a single number. This makes it
possible to evaluate METG at different node counts (shown in
Figure~\ref{fig:metg-compute}) to see how it is impacted by changes in
communication topology and latency.

In general, the least complicated pattern (stencil) is most favorable
to MPI, as it represents a truly bulk synchronous task graph with no
opportunity for task parallelism. For the stencil pattern, the
dominating factor is the basic overhead of executing a task, which is
minimal for MPI as the Task Bench implementation is bulk synchronous
and simply executes tasks one after another in alternation with
communication phases. In contrast the asynchronous execution
mechanisms of the other systems is pure overhead in this scenario.

The gap between MPI and other systems shrinks as the complexity of the
communication pattern grows, can even reverse as task parallelism is
added in the form of multiple task graphs.

% FIXME: update this when we have more data

Most systems for high-performance computing are horizontally scalable,
but this is not true of all the systems included in this
evaluation. Lower is better in Figure~\ref{fig:metg-compute}, and a
flat line is ideal. Systems with non-scalable implementations shows
lines that go up with node count. Most notably, Spark is typically
intended for use in industrial data center applications with task
granularities measured in tens of seconds. Spark uses a centralized
controller which limits throughput, and this is visible in the figure
as line for Spark immediately rises with node count. Keep in mind also
that Spark is being evaluated here with a non-trivial dependence
pattern which is relatively unrepresentative of Spark's normal use
cases. Spark is more efficient with trivial parallelism, as described
in Section~\ref{subsec:number-of-dependencies}.

% FIXME: talk about starpu and parsec?

% FIXME: talk about overhead spanning 5 orders of magnitude

\subsection{Number of Dependencies}
\label{subsec:number-of-dependencies}

\input{e4_radix}

\subsection{Load Imbalance}

\input{e5_imbalance}

\subsection{Communication Hiding}

\input{e6_communication}

\subsection{Comparison with Published Results}
