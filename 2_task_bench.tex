\section{Task Bench}
\label{sec:task-bench}

\input{t2_parameters}

\brokenpenalty=0

To explore as broad a space of application scenarios as possible, Task
Bench provides a large number of configuration parameters. The most
important parameters are described in
Table~\ref{tab:parameters}. These parameters control the size and
structure of the task graph, the type and duration of the kernels
associated with each task, and the amount of data associated with
each dependence edge in the graph.

\brokenpenalty=\oldbrokenpenalty

Task graphs are a combination of an \emph{iteration space} (with a task for
each point in the space) with a \emph{dependence relation}.
For simplicity, but without loss of generality, the iteration space in
Task Bench is constrained to be 2-dimensional, with time along
the vertical axis and parallel tasks along the
horizontal. Tasks may depend only on tasks from the immediately
preceding time step. Figure~\ref{fig:task-graphs} shows a number of sample task
graphs that can be implemented with Task Bench. Note that layout is
significant: generally speaking each column will be
assigned to execute on a different processor core.

Dependencies between tasks are controlled by a configurable dependence
relation. The
dependence relation enumerates the set of tasks from the
previous time step each task depends on, permitting a wide variety
of patterns to be implemented that are relevant to real
applications: stencils,
sweeps, FFTs, trees, etc. Dependence relations may be
parameterized, such as picking the $K$ nearest neighbors, or $K$
distant neighbors. They may also vary over time, such as in the FFT pattern. The set of dependence relations is extensible, making it easy to add patterns to represent new classes applications. Table~\ref{tab:equations} shows equations for the
dependence relations of the patterns in Figure~\ref{fig:task-graphs},
where $t$ is timestep, $i$ is column, and $W$ is the width of the task
graph.

\input{f5_task_graphs}
\input{t0_equations}

Listing~\ref{lst:code-sample} shows an excerpt from the Task Bench
implementation in MPI. Methods of the \lstinline{Graph} object
\lstinline{g} are provided by Task Bench's core API and are shared
among all implementations. These methods are summarized in
Table~\ref{tab:api}. The MPI implementation follows the style of
communicating sequential processes, and simply executes a set of send
and receive calls (lines 24 and 16, respectively) followed by
executing the task body (line 32). For simplicity, the excerpt
assumes the number of MPI ranks is equal to the width of the graph;
the full implementation is more general and provides additional
optimizations. Despite its simplicity, this MPI implementation is
among our best performing, and shows that Task Bench can be mapped to
idiomatic code even in programming systems with no native concept of
task.

%% (task(t,i) refers to the task at column i of timestep t)

In addition to specifying the shape and structure of the task graph, the
Task Bench core API also provides implementations of the kernels
executed by each task as well as other utility routines (to parse
inputs and display results). A sample of the core API compute kernel
is shown in Listing~\ref{lst:compute-kernel}. In addition to reducing
the effort required to implement Task Bench, providing central
implementations of these services ensures that all Task Bench
implementations can be scripted uniformly and eliminates a potential
source of performance disparity that can be a pitfall for mini-apps.

\input{t3_api}
\input{l0_compute_kernel}
%% \input{l1_code_sample}
\input{l2_mpi_sample}

\zap{
Despite its generality, Task Bench is easy to implement, making it
tractable to develop a suite of high-quality implementations. The central aspects of Task Bench, such as generating
task graphs and enumerating dependencies, are encapsulated in a core
library that is shared among all the Task Bench implementations. The
core library also includes implementations of the kernels, ensuring
that the kernels are identical in all systems, eliminating a potential
source of performance disparity that can be a pitfall for
implementations of mini-apps. Finally, the core library manages
parsing input parameters and displaying results,
ensuring that all implementations behave uniformly and can
be scripted consistently. Because much of the functionality needed for
a Task Bench implementation is in the core library, implementations of
Task Bench are small: our 15 Task Bench implementations range from 88
to 1500 lines, with several hundred lines being
typical. Listings~\ref{lst:compute-kernel} and \ref{lst:code-sample}
show excerpts from the Task Bench core, and the Dask implementation,
respectively. Only the code in Listing~\ref{lst:code-sample} is
implemented for each system, minimizing the work required for each additional system.
} % zap

The Task Bench core library is fully
validating. Because the task graph configuration is explicitly
represented (though unmaterialized) in Task Bench, this representation
can be queried to determine exactly what dependencies a task should
expect. The output of every task in Task Bench is unique,
and all inputs are verified. An assertion is thrown if validation
fails. These checks ensure that every execution of Task Bench, if it
completes successfully, is correct. An evaluation of the performance impact of
validation showed it to be less than 3\% at the smallest task
granularities in any Task Bench implementation, with a negligible
effect on overall results.

Task Bench provides two main kernels that can be called from tasks:
compute- and memory-bound. The compute-bound
kernel executes a tight loop and is hand-written using AVX2 FMA
intrinsics. The memory-bound kernel performs sequential reads and
writes over an array, again with AVX2
intrinsics. The duration of both kernels can be configured by setting
the number of iterations to execute; we use this ability to simulate
the effects of varying application problem sizes. The memory-bound
kernel is carefully written to keep the working set size constant as
the number of iterations decreases, to avoid unwanted speedups due to
cache effects.
