\section{Task Bench}
\label{sec:task-bench}

\input{t2_parameters}

To explore as broad a space of application scenarios as possible, Task
Bench provides a large number of configuration parameters. These
parameters are described in
Table~\ref{tab:parameters}, and control the size and
structure of the task graph, the type and duration of kernels
associated with each task, and the amount of data associated with
each dependence edge in the graph.

Task graphs are a combination of an \emph{iteration space} (with a task for
each point in the space) with a \emph{dependence relation}.
For simplicity, but without loss of generality, the iteration space in
Task Bench is constrained to be 2-dimensional, with time along
the vertical axis and parallel tasks along the
horizontal. Tasks may depend only on tasks from the immediately
preceding time step. Figure~\ref{fig:task-graphs} shows a number of sample task
graphs that can be implemented with Task Bench. Note that layout is
significant: generally speaking each column will be
assigned to execute on a different processor core.

Dependencies between tasks are determined by a dependence
relation. The
dependence relation identifies the tasks from the
previous time step each task depends on, permitting a wide variety
of patterns to be implemented that are relevant to real
applications: stencils,
sweeps, FFTs, trees, etc. Dependence relations may be
parameterized, such as picking the $K$ nearest neighbors, or $K$
distant neighbors. They may also vary over time, such as in the FFT pattern. The set of dependence relations is extensible, making it easy to add patterns to represent new classes of applications. Table~\ref{tab:equations} shows equations for the
dependence relations of the patterns in Figure~\ref{fig:task-graphs},
where $t$ is timestep, $i$ is column, and $W$ is the width of the task
graph.

\input{f5_task_graphs}
\input{t0_equations}

Listing~\ref{lst:code-sample} shows an excerpt from the Task Bench
implementation in MPI. Methods of the \lstinline{Graph} object
\lstinline{g} are provided by Task Bench's core API and are shared
among all implementations. These methods are summarized in
Table~\ref{tab:api}. The MPI implementation follows the style of
communicating sequential processes (CSP), and executes a set of send
and receive calls (lines 24 and 16, respectively) followed by
executing the task body (line 32). Despite MPI having no notion of
task, the execution of a task graph maps into the CSP style in a
straightforward way. The implementation is both simple and efficient,
but do to the choice of CSP makes no attempt to exploit task
parallelism, and leaves performance on the table when executing task
graphs with load imbalance or communication. Note the excerpt is
simplified for presentation and the full implementation is more
general and provides additional optimizations.

%% (task(t,i) refers to the task at column i of timestep t)

In addition to specifying the shape of the task graph, the
core API also provides implementations of the kernels
executed by each task as well as other utility routines (to parse
inputs and display results). An excerpt from the core API compute kernel
is shown in Listing~\ref{lst:compute-kernel}. In addition to reducing
the effort required to implement Task Bench, providing central
implementations of these services ensures that all Task Bench
implementations can be scripted uniformly and eliminates a potential
source of performance disparity that can be a pitfall for other benchmarks.

\zap{
Despite its generality, Task Bench is easy to implement, making it
tractable to develop a suite of high-quality implementations. The central aspects of Task Bench, such as generating
task graphs and enumerating dependencies, are encapsulated in a core
library that is shared among all the Task Bench implementations. The
core library also includes implementations of the kernels, ensuring
that the kernels are identical in all systems, eliminating a potential
source of performance disparity that can be a pitfall for
implementations of mini-apps. Finally, the core library manages
parsing input parameters and displaying results,
ensuring that all implementations behave uniformly and can
be scripted consistently. Because much of the functionality needed for
a Task Bench implementation is in the core library, implementations of
Task Bench are small: our 15 Task Bench implementations range from 88
to 1500 lines, with several hundred lines being
typical. Listings~\ref{lst:compute-kernel} and \ref{lst:code-sample}
show excerpts from the Task Bench core, and the Dask implementation,
respectively. Only the code in Listing~\ref{lst:code-sample} is
implemented for each system, minimizing the work required for each additional system.
} % zap

The Task Bench core library is fully self-validating: The output of each
task is a tuple $\langle \textrm{row, col}\rangle$ and is unique for a given task
graph. Inputs are verified by checking the expected dependencies
against those received, and an assertion is thrown if validation
fails. These checks ensure that every execution of Task Bench is
correct. Note that the graph representation is concise, making these
checks very inexpensive. An evaluation of the performance impact of
validation showed it to be less than 3\% at the smallest task
granularities in any Task Bench implementation, with a negligible
effect on overall results.

\input{t3_api}
\input{l0_compute_kernel}
%% \input{l1_code_sample}
\input{l2_mpi_sample}

Task Bench provides two main kernels that can be called from tasks:
compute- and memory-bound. The compute-bound
kernel executes a tight loop and is hand-written using AVX2 FMA
intrinsics. The memory-bound kernel performs sequential reads and
writes over an array, again with AVX2
intrinsics. The duration of both kernels can be configured by setting
the number of iterations to execute; we use this ability to simulate
the effects of varying application problem sizes. The memory-bound
kernel is carefully written to keep the working set size constant as
the number of iterations decreases, to avoid unwanted speedups due to
cache effects.
