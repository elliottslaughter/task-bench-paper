\section{Task Bench}
\label{sec:task-bench}

To measure a wide variety of
systems and application scenarios, we developed a novel
\emph{parameterized} benchmark called Task Bench. Task Bench
implementations execute a \emph{task graph}, with tasks for each point
in an \emph{iteration space} and dependencies between tasks determined
by a \emph{dependence relation}. A task that depends on another task
must execute after that task, and receives the output data from that
task as input. Each task can execute any one of a
number of kernels (compute-bound, memory-bound, etc.) and can generate
a configurable amount of output to control the amount of communication
performed with each task dependency. Thus Task Bench can explore a large space of application scenarios to
understand the performance of parallel and
distributed programming systems.

For simplicity, but without loss of generality, the iteration space in
Task Bench is constrained to be 2-dimensional, with time along
the vertical axis and parallel tasks along the
horizontal. Tasks can depend only on tasks from the immediately
preceding time step. Figure~\ref{fig:task-graphs} shows a number of sample task
graphs that can be implemented with Task Bench. Note that layout is
significant---in particular, each column $i$ corresponds to all tasks
with index $i$ in the iteration space over all the time
steps. Generally speaking each column of the task graph will be
assigned to execute on a different processor core.

Dependencies between tasks are controlled by a configurable dependence
relation. The
dependence relation enumerates, for each task, the set of tasks in the
previous time step that task depends on. This permits a wide variety
of dependence patterns to be implemented that are relevant to real
applications in high-performance scientific computing and data analysis: stencils,
sweeps, FFTs, trees, and so on. Dependence patterns may also be
parameterized, such as picking the $K$ nearest neighbors, or $K$
distant neighbors. Table~\ref{tab:equations} show equations for the
dependence relations of the patterns in Figure~\ref{fig:task-graphs},
where $t$ is timestep, $i$ is column, and $W$ is the width of the task
graph.

\input{f5_task_graphs}
\input{t0_equations}

Despite its generality, Task Bench is easy to implement, making it
tractable to develop a suite of high-quality implementations. The core aspects of Task Bench, such as generating
task graphs and enumerating dependencies, are encapsulated in a core
library that is shared among all the Task Bench implementations. The
core library also includes implementations of the kernels, ensuring
that the kernels are identical in all cases, eliminating a potential
source of performance disparity that can be a pitfall for
implementations of mini-apps. Finally, the Task Bench core library manages the
parsing of input parameters and the display of output results,
ensuring that all implementations behave in a uniform manner, and can
be scripted consistently. Because much of the functionality needed for
a Task Bench implementation is in the core library, implementations of
Task Bench are small: Our 13 Task Bench implementations range from 88
to 1500 lines, with several hundred lines being typical.

The Task Bench core library is fully
validating. Because the task graph configuration is explicitly
represented (though unmaterialized) in Task Bench, this representation
can be queried to determine exactly what dependencies a task should
expect. The output of every task in Task Bench is unique,
and all inputs are verified. An assertion is thrown if validation
fails. This level of self-checking ensures that every execution of Task Bench, if it
completes successfully, is correct. An evaluation of the impact of
validation showed it to be less than 3\% at the smallest task
granularities in any Task Bench implementation, with a negligible
effect on overall results.

Task Bench provides two main kernels that can be called from tasks,
which are compute- and memory-bound, respectively. The compute-bound
kernel executes a tight loop and is hand-written using AVX2 FMA
intrinsics. The memory-bound kernel performs sequential reads and
writes over an array, and is again hand-optimized with AVX2
intrinsics. The duration of both kernels can be configured by setting
the number of iterations to execute; we use this ability to simulate
the effects of varying application problem sizes. The memory-bound
kernel is carefully written to keep the working set size constant as
the number of iterations decrease, to avoid unwanted speedups due to
cache effects.
