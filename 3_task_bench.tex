\section{Task Bench}
\label{sec:task-bench}

In order to measure properties such as METG for a wide variety of
systems and application scenarios, we developed a novel
\emph{parameterized} benchmark called Task Bench. Task Bench
implementations execute a \emph{task graph}, with tasks for each point
in an \emph{iteration space} and dependencies between tasks determined
by a \emph{dependence relation}. Each task can execute any one of a
number of kernels (compute-bound, memory-bound, etc.) and can generate
a configurable amount of result data in order to control the amount of
communication that must be performed with each task dependency. Thus Task Bench can be used to
rapidly explore a large space of possible application scenarios in
order to understand the performance behaviors of parallel and
distributed languages and runtime systems.

For simplicity but without loss of generality, the iteration space in
Task Bench is constrained to be 2-dimensional, with time flowing along
the vertical axis and parallel tasks along the
horizontal. Tasks can depend only on tasks from the immediately
preceding time step. Many problems can be described by a task graph of
constant width, in which case the iteration space is rectangular, but
Task Bench is capable of handling non-rectangular iteration spaces,
such as required by sweeps and tree-based dependence
patterns. Figure~\ref{fig:task-graphs} shows a number of sample task
graphs that can be implemented with Task Bench.

% FIXME: Make figure showing example task graphs

Dependencies between tasks are controlled by a configurable dependence
relation. Dependencies are conceived as flowing backwards in time. The
dependence relation enumerates for each task, the set of tasks in the
previous time step that task depends on. This permits a wide variety
of dependence patterns to be implemented that are relevant to real
applications in high-performance scientific computing: stencils,
sweeps, FFTs, trees, and so on. Dependence patterns may also be
parameterized, such as picking the $K$ nearest neighbors, or $K$
distant neighbors. These dependence patterns can be seen in
Figure~\ref{fig:task-graphs}.

Despite its generality, Task Bench is easy to implement, making it
tractable to develop a suite of high-quality implementations. Most
Task Bench implementations are several hundred lines long, with the
shortest being 88 lines and the longest being 1500 lines of executable
code. Much of this is possible because the core aspects of generating
task graphs and enumerating dependencies are encapsulated in a core
library that is shared among all the Task Bench implementations. The
core library also includes implementations of the kernels, ensuring
that the kernels are identical in all cases, eliminating a potential
source of performance disparity which can be a pitfall for mini-apps
implementations. Finally, the Task Bench core library manages the
parsing of input parameters and the display out output results,
ensuring that all implementations behave in a uniform manner, and can
be scripted consistently.

The task implementation in the Task Bench core library is fully
validating. Because the task graph configuration is explicitly
represented (though unmaterialized) in Task Bench, this representation
can be queried to determine exactly what dependencies a task should
expect. The output of every task in Task Bench is uniquely generated,
and all inputs are verified. An assertion is thrown if validation
fails. This ensures that every execution of Task Bench, if it
completes successfully, is correct. This validation provides high
assurance that all Task Bench implementations are correct, and
safeguards against corner cases that may only be exercised at
scale. An evaluation of the performance impact of
this validation showed it to be less than 3\% at the smallest task
granularities in any Task Bench implementation, with a negligible
effect on overall results.
