\section{Performance Issues Discovered}
\label{sec:case-study}

Task Bench is useful not only as a tool for evaluating programming
system performance, but also for discovering potential areas for
improvement. During the development of Task Bench, we identified a
number of performance issues in the underlying programming
systems. These discoveries were possible because of the flexibility of
Task Bench, and our ability to rapidly run new experiments with a
variety of application scenarios. All issues were reported to and
acknowledged by the respective system's developers, and are either
fixed or worked around in our experiments. We describe them below.

Realm and Chapel both use DMA subsystems optimized for large
copies. Early Task Bench experiments revealed high METG values,
diagnosed by the Realm/Chapel developers as overhead due to the
cost of scheduling small copies. Subsequent improvements in Realm and
Chapel improved small copy overheads (and thus METG) by over an order
of magnitude in the case of Realm, and by $2\times$ in the case of
Chapel. These improvements affect any application where fine-grained
data movement is needed, which is particularly relevant in strong scaling
regimes when running on large numbers of nodes.

{\color{blue}
Further analysis of Realm efficiency indicated many overheads due to
dynamic graph construction. The Realm developers implemented a new
``subgraph'' API in response to this feedback to amortize the cost of
repeatedly constructing isomorphic task graphs. This API is used in
Task Bench to achieve further speedups in the Realm implementation.

Chapel uses a naive round-robin scheduler by default, which can lead
to unexpected load balance issues because certain language features
(such as remote array assignment) implicitly generate tasks. This
resulted in poor peak performance, even at large task granularities,
which in some cases made it impossible to measure METG (because peak
efficiency did not exceed 50\%). Chapel's other schedulers add
overhead, resulting in higher METGs. We worked around this with
a \lstinline{serial} block.

PaRSEC uses task pruning to reduce analysis work performed on each
node, and thus improve scalability at large node
counts. Initial Task Bench results achieved less than the expected
scalability: METG was rising too quickly with node count.  The PaRSEC
developers diagnosed a bug in task pruning---the optimization was failing to trigger---and it was
subsequently fixed. We also implemented a version of the PaRSEC code,
\lstinline{shard}, which uses manual pruning to demonstrate that
additional gains may still be possible.

Early Task Bench results for Dask revealed that the cost of scheduling
a task was $\mathcal{O}(N)$ where $N$ is the number of tasks in a task
graph, causing overall cost for a task graph with $N$ nodes to be
$\mathcal{O}(N^2)$. This issue was reported to and confirmed by the
Dask developers; the bug is suspected to be in optimizations performed
on the task graph by Dask. As a work around, our results in the paper use a
lower-level interface which does not suffer from this asymptotic
slowdown.

Initial experiments with TensorFlow revealed that the Task
Bench implementation was not able to use all cores on a node (making it impossible to measure METG since efficiency was below
50\%). The TensorFlow developers diagnosed this as an issue in
constant folding. The entire Task Bench task graph was being detected
as constant, and the constant-folding pass runs on one core. As a
workaround, the developers suggested marking the task graph inputs as
non-constant so that TensorFlow's standard task scheduler could be
used.

In all cases, we found bugs that are applicable outside of Task Bench
and that impact metrics other than METG. Notably, the scalability
issues and asymptotic complexity have a growing impact with larger
node counts and will eventually become visible with nearly any
application. In other cases, Task Bench and METG made it possible to
identify performance degradation at the extremes of application
configurations which might remain hidden with full-size applications,
particularly when evaluated with weak and strong scaling alone. The
improvements motivated by our findings are nonetheless relevant in
strong-scaling regimes in a variety of applications, particularly as
node and core counts grow.

} % color

\zap{
We found further areas for improvement in schedulers (Realm, Chapel
and Dask), task pruning for scalability (PaRSEC), and optimizations on
the task graph (TensorFlow). The impact of these optimizations ranged
from small constant factors to even asymptotic improvements in
performance and scalability (in the case of PaRSEC and Dask). All
users will benefit from the improvements driven by our discoveries.
} % zap
